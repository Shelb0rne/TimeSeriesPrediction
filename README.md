# Прогнозирование временных рядов температуры
## Цель проекта

Исследовать данные температуры воздуха, построить и сравнить разные модели прогнозирования временных рядов: Ridge Regression, XGBoost и LSTM.
Сравнить их по метрикам MSE и R², а также по визуализации предсказаний.

## Датасет

Источник: weatherHistory.csv ( https://www.kaggle.com/datasets/muthuj7/weather-dataset )

Поля:

- Formatted Date — дата измерения

- Temperature (C) — температура воздуха

Объём: ~96 тыс. наблюдений

Частота: почасовые данные

## Предварительный анализ

Гистограмма распределения температуры

<img width="720" height="564" alt="Снимок экрана 2025-09-04 011608" src="https://github.com/user-attachments/assets/ceada5bb-930c-413a-a103-82b9b70b8c2f" />

Гистограмма распределения температуры показывает близость к нормальному распределению, но с лёгкой асимметрией.

Q-Q plot (проверка нормальности)

<img width="711" height="568" alt="Снимок экрана 2025-09-04 011627" src="https://github.com/user-attachments/assets/5f2f618f-0760-432f-9ca0-4ad4475d21dc" />

Q-Q plot указывает на отклонения в хвостах, что подтверждает наличие выбросов.

Boxplot (поиск выбросов)

<img width="686" height="513" alt="Снимок экрана 2025-09-04 011641" src="https://github.com/user-attachments/assets/c7879b96-9b7e-4592-bc35-6487e923d276" />

Boxplot выявил экстремальные низкие значения (ниже –20 °C).

Временной ряд температуры

<img width="1387" height="476" alt="Снимок экрана 2025-09-04 011652" src="https://github.com/user-attachments/assets/f3081985-495e-4eb9-b7e3-3e86b2c30b3a" />

Временной ряд: видны сильные колебания, характерные для погодных данных.

## Генерация признаков

Использованы лаговые признаки (температура N шагов назад). Добавлены скользящие статистики (среднее, стандартное отклонение, дисперсия, ассиметрия, эксцесс и др).

Сгренерировано более 200 признаков.

Применён forward selection для отбора наиболее значимых признаков.

График Forward Selection:

<img width="1072" height="678" alt="Снимок экрана 2025-09-04 011706" src="https://github.com/user-attachments/assets/94754d0f-7711-4c87-97b2-29e70b858a00" />

Вывод: оптимальное число признаков — 21, дальнейшее добавление мало влияет на качество.

## Модели и результаты
1. Ridge Regression

Метрики:

MSE: 0.027

R²: 0.968

График предсказаний:

<img width="1386" height="501" alt="Снимок экрана 2025-09-04 011720" src="https://github.com/user-attachments/assets/fd3400e5-82f0-4a80-be6c-b0fe970af760" />

2. XGBoost Regressor

Метрики:

MSE: 0.019

R²: 0.977

График предсказаний:

<img width="1387" height="499" alt="Снимок экрана 2025-09-04 011730" src="https://github.com/user-attachments/assets/edeaea95-3675-4c73-af46-ebfc48ae1157" />


3. LSTM

Метрики:

MSE: 0.034

R²: 0.96

График процесса обучения (Train/Test Loss):

<img width="701" height="563" alt="Снимок экрана 2025-09-04 012049" src="https://github.com/user-attachments/assets/983d9d3a-ff14-4e48-9bbd-0b7c60a1f182" />


## Сравнение моделей

Сравнительный график R² Score:

<img width="1243" height="656" alt="Снимок экрана 2025-09-04 014246" src="https://github.com/user-attachments/assets/f3e5585d-f87e-428d-9dd7-5262871da4a0" />


## Выводы

Данные температуры имеют близкое к нормальному распределение, но есть выбросы.

Все модели показали высокое качество (R²≈0.96–0.98).

XGBoost оказался немного лучше остальных.

LSTM показала стабильное обучение и сопоставимые результаты, но требует больше ресурсов.

Автор: Цуркан Игорь
